
#The question of reproducibility in brain imaging {.step data-scale=10}


## Jean-Baptiste Poline  

Brain Imaging Center, Helen Wills Neuroscience Institute, UC Berkeley


# Outline
>     
> * Science Reproducibility crisis evidence
> * Causes and Impact
> * What about brain imaging ? Some - but few - facts
> * What shall we do about it 

# Science finding Reproducibility crisis evidence

## Preclinical oncology

> * Begley C.G. & Ellis L. Nature, (2012): "6 out of 53 key findings could not be replicated"

## Epidemiology

> * Ioannidis 2011: “The FP/FN Ratio in Epidemiologic Studies:” 

## In social sciences and in psychology

> * Reproducibility Project: Psychology (open science foundation)
> * Simmons, et al. “... Undisclosed Flexibility ... Allows Presenting Anything as Significant.” 2011. 
> * In cognitive neuroscience:  Barch, Deanna M., and Tal Yarkoni. “Special Issue on Reliability and Replication in Cognitive and Affective Neuroscience Research.”  2013.

---------------

## Genetics

> * Ionannidis 2007: 16 SNPs hypothesized, check on 12-32k cancer/control: "... results are largely null." 
> * The concept of endophenotype
> * Many references and warning: eg:"Drinking from the fire hose ..." by Hunter and Kraft, 2007.

## Neuroscience

> * Button et al., 2013

## In general: Editorials / high profile journals

> * In general: Nature, "Reducing our irreproducibility", 2013.
    - New mechanism for independently replicating needed 
    - Easy to misinterpret artefacts as biologically important
    - Too many sloppy mistakes 
    - Revised standard for statistical evidence (PNAS 2013)

---------------

# What about brain imaging ? Some - _but few_ - facts

> * Jossua Carp (2013): report does not allow replication of to find methodological issues
    """ For example, while Brown and Braver (2005) claimed
    that activation in the anterior cingulate cortex (ACC) is
    sensitive to the likelihood of committing an error,
    Nieuwenhuis, Tanja, Mars, Botvinick, and Hajcak (2007)
    reported no relationship between ACC activation and error
    likelihood."""

> * Analysis of large databases showing low condordance of small sample group analysis (Thirion et al., 2007)

> * Reproducibility: confirmed to be very poor by some 
    - Boekel, W., et al. (2013). A purely confirmatory
      replication study of structural brain-behavior
      correlations. Journal of Neuroscience 12, 4745–4765.
    - 5 studies, 17 findings : Baysian analysis favored null hypothesis
    - Problem: only 36 subjects, while most original studies
> * The Autism example: Toro et al., Corpus callosum size example.

# Causes and Impact

> * Statistical 
> * Computational 
> * Social 

----------------------------

## Statistical causes:

> * Lack of understanding of statistical issues and Power computation
> * The usual issues apply:
    > - low power studies (Button et al, 2013)
    > - P-hacking: Simmons et al. 2011, Simmonshon et al., 2014
> * P value evil: when will we turn to Baysian evidence?
> * File drawer problem: emmergence of complex H0/H1


----------------------------

## Computational causes:

> * Biologists and MDs are rarely appropriately trained in computation - but most brain imaging findings rely heavily on computations
> * Clairebout's "Publication is an advertisement, scholarship lies in the code" (Truer for applied math field, but also valid in Brain Imaging if models are included)
> * Meta data capture and curation not implemented (parameters and process of data generation), no standards for meta data
> * Computational environment packaging not used enough (cf Neurodebian)

----------------------------

## Social causes

> * High pressure for publication in competitive environment
> * Publication based reward system (carreer, grants, fame, etc) is not working towards good science (careful, replicated, reproduced)
> * The file drawer problem: how this can delay scientific revolution (A. Afraz, 'We could all be astronomers')
> * System favors high risk project and publication 

----------------------------


## Impact

> * Large amount of resource wasted (talent, money, time)  
> * Discredit from the public and governments
> * Slows down scientific and medical progress
> * Impact on the type of work that can be started (counter example: biobank, bavarian cohorts).
> * Increase young generation cynicism 

# Conclusion: What shall we do about it 

> * Adopt more stringent and better statistical and computational standards 
> * Augment the awareness of these issues, advocate for data and code sharing as the standard in our field
> * Adopt genetic research standards: every result should be replicated 
> * Adopt clinical trial standards and pre-registration
> * Train the new generation of scientist in computation, statististics

# Acknowledgement & Conclusion 

* My colleagues at Berkeley  (M. Brett, J. Millman, F. Perez, the Simpace group)
* My colleagues at INCF (Mathew Abrams, Linda Layon)
* My colleagues of Nidash (David Kennedy, Satra Ghosh, Chris Gorgowleski, Nolan Nichols, Dave Keator, Camille Maumet, Guillaume Flandin, Tom Nichols, Russ Poldrack, etc)





